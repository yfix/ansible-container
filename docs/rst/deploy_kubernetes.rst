
Deploy to Kubernetes
====================

The ``ansible-container shipit`` command brings the power of Ansible to container deployment, making it easy to
automate the deployment of your application on Kubenetes, OpenShift and more. In this example we'll see how to deploy
to `Google Container Engine <https://cloud.google.com/container-engine/>`_ using *shipit*.

Requirements
''''''''''''
Follow the `installation guide <http://docs.ansible.com/ansible-container/installation.html>`_ to install ansible-container
from source.

In addition to Ansible Container, the following are also required to run the complete deployment workflow:

+ Ansible 2.0+
+ kubectl
+ Kubernetes cluster hosted on Google Compute Engine
+ access to a Docker daemon for building and pushig images

The Ansible role generated by *shipit* includes multiple Ansible modules in the role *library* directory that interact
with the Kubernetes cluster to create services and deployments. Communication wth the cluster is performed using the
*kubectl* client. To run the role, the *kubectl* client must be installed.

See the `Google Cloud SDK - Getting Started <https://cloud.google.com/sdk/docs/>`_ for instructions on installing the
SDK and *kubectl*. There is also an Ansible role, `ansible.install-gcloud <https://galaxy.ansible.com/ansible/install-gcloud/>`_
to help automate the installation.

To complete the deployment you will need a Kubernetes cluster hosted at `Google Compute Engine <https://cloud.google.com/compute/>`_.
If you don't have an account, create a free account. You will receive a $300 credit, which is way more than you will need for this example.
Once you sign in, follow the `Quickstart Guide <https://cloud.google.com/container-engine/docs/quickstart>`_ to create a project and a
Google Container Engine cluster.

Assumptions
'''''''''''

For the purposes of this example, Kubernetes will refer to `Google Container Engine <https://cloud.google.com/container-engine/>`_.
The private registry used in the examples is `Google Container Registry <https://cloud.google.com/container-engine/>`_. A project
is a project created on `Google Compute Engine <https://cloud.google.com/compute/>`_, and a cluster is a cluster created in the project
using Google Container Engine.


Client Authentication
'''''''''''''''''''''

To authenticate with Kubernetes (Google Contaner Engine), you can manually run ``gcloud init``. A better way, and a way that
can be easily automated is to create a `service account <https://cloud.google.com/compute/docs/access/create-enable-service-accounts-for-instances>`_
and use the associated JSON key file.

Once you have your service account, download the JSON key file. This is a private key for accessing the cluster. Secure it just as you would
an SSH private key file.

Use the following command, changing the path and name of the key file, to authenticate with the cluster:

.. code-block:: bash

    $ gcloud auth activate-service-account --key-file ~/path/to/sercure/Keyfile_XXXXXXXX.json

The above command will add your credentials to the list of available configurations and make it the default. To see
all available configurations:

.. code-block:: bash

    $ gcloud config configurations list

Use the ``gcloud config set`` command to adjust the Project, Default Zone and Default Region settings.

.. code-block:: bash

    $ glcoud config set project foo

.. code-block:: bash

    $ gcloud config set compute/zone zone3

To change the active account:

.. code-block:: bash

    $ gcloud auth login <email_address>@<project-id>.iam.gserviceaccount.com --activate


Deployment
''''''''''
In this walk through we'll demonstrate deploying `the example application <https://github.com/ansible/ansible-container/tree/master/example>`_
found in the ansible-container repo. Here's the workflow we'll follow to deploy the application on a Kubernetes cluster using Ansible Container:

+ Build the images with ``ansible-container build``.
+ Push the new images to the cloud with ``ansible-container push``.
+ Create the deployment role and playbook with ``ansible container shipit kube``.
+ Run the playbook with ``ansible-playbook shipit_kubernetes.yml``.

Build the Images
----------------

Using the example project, build the images

.. code-block:: bash

    $ cd example
    $ ansible-container build

Use `docker images` to view the available images:

.. code-block:: bash

    $ docker images

    REPOSITORY                                   TAG                 IMAGE ID            CREATED             SIZE
    example-django                               20160622155105      2463f6029944        3 hours ago         794.8 MB
    example-django                               latest              2463f6029944        3 hours ago         794.8 MB
    example-postgresql                           20160622155105      e936d28ff596        3 hours ago         764.1 MB
    example-postgresql                           latest              e936d28ff596        3 hours ago         764.1 MB
    example-static                               20160622155105      c1a1f10afd4e        3 hours ago         796 MB
    example-static                               latest              c1a1f10afd4e        3 hours ago         796 MB
    example-gulp                                 20160622155105      a06c743d37e2        3 hours ago         331 MB
    example-gulp                                 latest              a06c743d37e2        3 hours ago         331 MB


Pushing Images to the Cloud
---------------------------

For the deployment to work, the cluster will need access to the new images. This requires pushing them into a registry
that the cluster can pull from. The push can be done using the ``ansible-contianer push`` command.

If you're using a secure registry, you will first need to authenticate with the registry. You can authenticate using ``docker login``,
or pass your credentials to ``ansible-cotainer push``. If you used a service account with a JSON key file, you can use
the JSON key file to authenticate with Google Container Registry. For example:

.. code-block:: bash

    $ ansible-container push --username _json_key --password "$(cat ~/path/to/Keyfile_XXXXXXXX.json)" --url https://gcr.io --namespace my-project-id-XXXX

Using a key file requires setting the username to *_json_key*. For container engine images must be namespaced by the project ID.
The --namespace option in the above statement sets the namespace for each images to the project ID. If a namespace is not provided, the username is
used as the namespace, which will not work. Make sure to use the correct ID for your project.

After authenticating for the first time, Docker will update your ~/.docker/config.json file with the registry url and your credentials. This is true whether
you used ``docker login`` or ``ansible-container push`` to authenticate. Going forward you will no longer need to provide your credentials to push images
to https://gcr.io.

For convenience, you can add an entry to the *registries* key in your container.yml file to enable --push-to and --pull-from command line
options. You can use those options in place of --url and --namespace. For example, adding the following to container.yml:

.. code-block:: bash

    registries:
        google:
            url: https://gcr.io
            namespace: fab-project-xxxxx

enables use of the *--push-to* option:

.. code-block:: bash

    $ ansible-container push --push-to google


Shipit - Build the Deployment Role
----------------------------------

Next, run the *shipit* command to generate the role and playbook. If you created an entry in container.yml for google, as described above, you
can use the *--pull-from* command line option.

.. code-block:: bash

   $ ansible-container shipit --pull-from google

The *--pull-from* option tells the shipit command how to reference the images needed to build containers on the cluster. Without *--pull-from*
the cluseter will attempt to pull images from Docker Hub namespaced with your username.

Run the Role
------------

The playbook and role are added to the ansible directory. Run the playbook from inside the ansible directory:

.. code-block:: bash

    $ cd ansible
    $ ansible-playbook shipit_kubernetes.yml

    [WARNING]: Host file not found: /etc/ansible/hosts

    [WARNING]: provided hosts list is empty, only localhost is available


    PLAY [Deploy example to  kubernetes] *******************************************

    TASK [example_kubernetes : kube_service] ***************************************
    changed: [localhost]

    TASK [example_kubernetes : debug] **********************************************
    skipping: [localhost]

    TASK [example_kubernetes : kube_service] ***************************************
    changed: [localhost]

    TASK [example_kubernetes : debug] **********************************************
    skipping: [localhost]

    TASK [example_kubernetes : kube_service] ***************************************
    changed: [localhost]

    TASK [example_kubernetes : debug] **********************************************
    skipping: [localhost]

    TASK [example_kubernetes : kube_deployment] ************************************
    ok: [localhost]

    TASK [example_kubernetes : debug] **********************************************
    skipping: [localhost]

    TASK [example_kubernetes : kube_deployment] ************************************
    changed: [localhost]

    TASK [example_kubernetes : debug] **********************************************
    skipping: [localhost]

    TASK [example_kubernetes : kube_deployment] ************************************
    changed: [localhost]

    TASK [example_kubernetes : debug] **********************************************
    skipping: [localhost]

    TASK [example_kubernetes : kube_deployment] ************************************
    changed: [localhost]

    TASK [example_kubernetes : debug] **********************************************
    skipping: [localhost]

    PLAY RECAP *********************************************************************
    localhost                  : ok=7    changed=6    unreachable=0    failed=0


View the Services and Deployments on Kubernetes
-----------------------------------------------

Use *kubectl* to list the services:

.. code-block:: bash

    $ kubectl get servies

    NAME         CLUSTER-IP     EXTERNAL-IP       PORT(S)    AGE
    django       10.3.243.23    nodes             8080/TCP   22m
    kubernetes   10.3.240.1     <none>            443/TCP    6d
    postgresql   10.3.246.164   nodes             5432/TCP   22m
    static       10.3.253.131   104.155.181.157   80/TCP     22m

Notice the static service has an external IP address. Point a browser at *http://<static service external IP>/admin*
to view the application. An external IP address is assigned to the static service because of the port directive in the
static service definition found in container.yml:

.. code-block:: bash

    static:
    image: centos:7
    ports:
      - "80:8080"
    user: 'nginx'
    links:
      - django
    command: ['/usr/bin/dumb-init', 'nginx', '-c', '/etc/nginx/nginx.conf']
    dev_overrides:
      ports: []
      command: /bin/false
    options:
      kube_runAsUser: 997

The ports list includes *80:8080*, which indicates that port 8080 from the container should be exposed as port 80 on the
host. The *shipit* command interprets this as port 80 should be exposed to the outside, as it would be when the application
is launched locally.

Now take a look at the deployments:

.. code-block:: bash

    $ kubectl get deployments

    NAME         DESIRED   CURRENT   UP-TO-DATE   AVAILABLE   AGE
    django       1         1         1            1           1h
    postgresql   1         1         1            1           1h
    static       1         1         1            1           1h


A deployment is a way to create resource controllers, pods and containers in a single step. It also comes with the ability
to automatically perform rolling updates during subsequent deployments, potentially eliminating any downtime for the
application.

Next, take a look at the pods created by the deployments:

.. code-block:: bash

    $ kubectl get pods

    NAME                          READY     STATUS    RESTARTS   AGE
    django-1184821742-93px6       1/1       Running   0          59s
    postgresql-2580868339-2qk2k   1/1       Running   0          1m
    static-3768509799-r3zbl       1/1       Running   0          1m

And finally, view the details for one of the pods:

.. code-block:: bash

   $ kubectl describe pods/django-1184821742-93px6

    Name:		django-1184821742-93px6
    Namespace:	default
    Node:		gke-ansible-container-default-pool-250ab39d-95nm/10.128.0.4
    Start Time:	Thu, 23 Jun 2016 05:42:59 -0400
    Labels:		app=example,pod-template-hash=1184821742,service=django
    Status:		Running
    IP:		10.0.1.3
    Controllers:	ReplicaSet/django-1184821742
    Containers:
      django:
        Container ID:	docker://82abefdd90ec336be30b69e0fa57656e3bb2bf72c39fbc15a5286ff7fc228435
        Image:		gcr.io/e-context-129918/example-django:20160622155105
        Image ID:		docker://515a604a99eb49253497130ecf34d3ca41634164bb8571dc4302f1c4c97efe9a
        Port:		8080/TCP
        Args:
          /usr/bin/dumb-init
          /venv/bin/gunicorn
          -w
          2
          -b
          0.0.0.0:8080
          example.wsgi:application
        QoS Tier:
          cpu:	Burstable
          memory:	BestEffort
        Requests:
          cpu:		100m
        State:		Running
          Started:		Thu, 23 Jun 2016 05:42:59 -0400
        Ready:		True
        Restart Count:	0
        Environment Variables:
    Conditions:
      Type		Status
      Ready 	True
    Volumes:
      default-token-728nf:
        Type:	Secret (a volume populated by a Secret)
    SecretName:	default-token-728nf

The above reveals some of the details of the configuration used to create the pod and container. Notice the image value in the
example is *gcr.io/e-context-129918/example-django:20160622155105*. This is the result of passing the *--pull-from* option to the *shipit*
command. To see the full configuration template run ``kubectl get pods/<name of the pod> -o json``.


ShipIt Role and Playbook Notes
------------------------------

A couple notes on the playbook run. The WARNING messages appear because there is no inventory file. The play in playbook
runs on localhost, which as the messages indicates, is actually available. For future runs You can ignore the
warnings by turning them off as discussed in `Ansible Configuration file <http://docs.ansible.com/ansible/intro_configuration.html>`_.
Or, create an inventory file with a single line:

.. code-block:: bash

    $ echo localhost >inventory

In subsequent playbook runs, include the *-i* option:

.. code-block:: bash

    $ ansible-playbook -i inventory shipit_kuberenete.yml

There are debug statements inserted into the role for each task. By default they do not execute, which is why the 'skipping: [localhost]'
messages appear. To see the output from the debug statements in future runs, set the variable *playbook_debug* to true.
For example:

.. code-block:: bash

    $ ansible-playbook shipit_kubernetes.yml -e "playbook_debug=true"

The output from the debug statements will show the data returned by each task in the role, which is helpful while
developing the role and adding additional tasks to it.







